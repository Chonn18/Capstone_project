{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "·∫¢nh nhi·ªÖu ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i /home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\n",
      "·∫¢nh nhi·ªÖu ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i /home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def add_horizontal_noise_rgb(img_tensor, intensity=0.1, stripe_width=1, randomize=False):\n",
    "    \"\"\"\n",
    "    Th√™m nhi·ªÖu horizontal tr·∫Øng ƒëen v√†o ·∫£nh RGB (3 k√™nh).\n",
    "    Args:\n",
    "        img_tensor (torch.Tensor): ·∫¢nh RGB d·∫°ng [3, H, W], gi√° tr·ªã [0,1]\n",
    "        intensity (float): M·ª©c ƒë·ªô nhi·ªÖu\n",
    "        stripe_width (int): ƒê·ªô d√†y c·ªßa c√°c s·ªçc nhi·ªÖu\n",
    "        randomize (bool): C√≥ random c∆∞·ªùng ƒë·ªô theo d√≤ng kh√¥ng\n",
    "    Returns:\n",
    "        torch.Tensor: ·∫¢nh RGB [3, H, W] ƒë√£ th√™m nhi·ªÖu tr·∫Øng ƒëen\n",
    "    \"\"\"\n",
    "    img_np = img_tensor.clone().cpu().numpy()\n",
    "    c, h, w = img_np.shape\n",
    "    assert c == 3, \"·∫¢nh ƒë·∫ßu v√†o ph·∫£i l√† RGB v·ªõi 3 k√™nh\"\n",
    "\n",
    "    # T·∫°o nhi·ªÖu d·∫°ng grayscale\n",
    "    noise = np.zeros((1, h, w), dtype=np.float32)\n",
    "\n",
    "    for row in range(0, h, stripe_width * 2):\n",
    "        stripe_noise = np.random.uniform(-intensity, intensity) if randomize else intensity\n",
    "        noise[:, row:row+stripe_width, :] = stripe_noise\n",
    "\n",
    "    # √Åp d·ª•ng nhi·ªÖu ƒë·ªÅu l√™n c·∫£ 3 k√™nh\n",
    "    noise = np.repeat(noise, 3, axis=0)  # [1, H, W] -> [3, H, W]\n",
    "\n",
    "    noisy_img = img_np + noise\n",
    "    noisy_img = np.clip(noisy_img, 0.0, 1.0)\n",
    "    return torch.from_numpy(noisy_img).to(img_tensor.device)\n",
    "\n",
    "def save_tensor_image(noisy_img, output_path):\n",
    "    img_np = noisy_img.detach().cpu().numpy()  # [C, H, W]\n",
    "    img_np = np.transpose(img_np, (1, 2, 0))    # ‚Üí [H, W, C]\n",
    "    img_np = (img_np * 255).astype(np.uint8)    # [0,1] ‚Üí [0,255]\n",
    "    img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)  # RGB ‚Üí BGR\n",
    "    cv2.imwrite(output_path, img_np)\n",
    "    print(f\"·∫¢nh nhi·ªÖu ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i {output_path}\")\n",
    "\n",
    "# Gi·∫£ s·ª≠ ·∫£nh input l√† RGB [3, H, W]\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "image_path = \"/home/duongnhan/Chon/MWFormer/data/CT/gt/image_s0001_i0021.jpg\"\n",
    "img = Image.open(image_path).convert(\"RGB\")\n",
    "img_tensor = T.ToTensor()(img)\n",
    "\n",
    "noisy_img = add_horizontal_noise_rgb(img_tensor, intensity=0.25, stripe_width=8, randomize=True)\n",
    "output_path = \"/home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\"\n",
    "save_tensor_image(noisy_img, output_path)\n",
    "print(f\"·∫¢nh nhi·ªÖu ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKh√¥ng th·ªÉ ƒë·ªçc ·∫£nh! Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Th√™m nhi·ªÖu Gaussian tr·∫Øng ƒëen\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# noisy_image = add_horizontal_noise(image)\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     noisy_img \u001b[38;5;241m=\u001b[39m add_horizontal_noise(\u001b[43mimg_tensor\u001b[49m, intensity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, stripe_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, randomize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# L∆∞u ·∫£nh k·∫øt qu·∫£\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def add_horizontal_noise(img_tensor, intensity=0.1, stripe_width=1, randomize=False):\n",
    "    \"\"\"\n",
    "    Th√™m nhi·ªÖu horizontal (d·∫°ng s·ªçc ngang) v√†o ·∫£nh.\n",
    "    \n",
    "    Args:\n",
    "        img_tensor (torch.Tensor): ·∫¢nh input d·∫°ng [C, H, W] v·ªõi gi√° tr·ªã [0, 1]\n",
    "        intensity (float): M·ª©c ƒë·ªô nhi·ªÖu (0.0 - 1.0)\n",
    "        stripe_width (int): ƒê·ªô d√†y c·ªßa m·ªói s·ªçc ngang\n",
    "        randomize (bool): N·∫øu True, nhi·ªÖu s·∫Ω thay ƒë·ªïi ng·∫´u nhi√™n theo t·ª´ng d√≤ng\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: ·∫¢nh v·ªõi nhi·ªÖu horizontal\n",
    "    \"\"\"\n",
    "    img_np = img_tensor.clone().cpu().numpy()\n",
    "    c, h, w = img_np.shape\n",
    "\n",
    "    noise = np.zeros((c, h, w), dtype=np.float32)\n",
    "\n",
    "    for row in range(0, h, stripe_width * 2):\n",
    "        stripe_noise = np.random.uniform(-intensity, intensity) if randomize else intensity\n",
    "        noise[:, row:row+stripe_width, :] = stripe_noise\n",
    "\n",
    "    noisy_img = img_np + noise\n",
    "    noisy_img = np.clip(noisy_img, 0.0, 1.0)\n",
    "    return torch.from_numpy(noisy_img).to(img_tensor.device)\n",
    "\n",
    "\n",
    "def add_gaussian_noise_grayscale(image, mean=0, sigma=35):\n",
    "    # Chuy·ªÉn ·∫£nh sang ki·ªÉu int16 ƒë·ªÉ tr√°nh tr√†n gi√° tr·ªã\n",
    "    image = image.astype(np.int16)\n",
    "    \n",
    "    # T·∫°o nhi·ªÖu grayscale (ch·ªâ m·ªôt k√™nh)\n",
    "    h, w, c = image.shape\n",
    "    noise = np.random.normal(mean, sigma, (h, w)).astype(np.int16)  # Ch·ªâ t·∫°o nhi·ªÖu cho 1 k√™nh\n",
    "\n",
    "    # √Åp d·ª•ng nhi·ªÖu l√™n c·∫£ 3 k√™nh m√†u\n",
    "    noisy_image = np.clip(image + noise[:, :, np.newaxis], 0, 255).astype(np.uint8)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "# ƒê·ªçc ·∫£nh\n",
    "image_path = \"/home/duongnhan/Chon/MWFormer/data/CT/gt/image_s0001_i0021.jpg\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n ·∫£nh c·ªßa b·∫°n\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh! Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.\")\n",
    "else:\n",
    "    # Th√™m nhi·ªÖu Gaussian tr·∫Øng ƒëen\n",
    "    # noisy_image = add_horizontal_noise(image)\n",
    "    noisy_img = add_horizontal_noise(img_tensor, intensity=0.05, stripe_width=2, randomize=True)\n",
    "\n",
    "    # L∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "    output_path = \"/home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\"\n",
    "    cv2.imwrite(output_path, noisy_image)\n",
    "    print(f\"·∫¢nh nhi·ªÖu ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i {output_path}\")\n",
    "\n",
    "    # Hi·ªÉn th·ªã ·∫£nh g·ªëc v√† ·∫£nh c√≥ nhi·ªÖu\n",
    "    # cv2.imshow(\"Original Image\", image)\n",
    "    # cv2.imshow(\"Noisy Image\", noisy_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def add_horizontal_noise(image, intensity=30, stripe_thickness=1, frequency=20):\n",
    "    noisy_image = image.copy()\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    for i in range(0, h, frequency):\n",
    "        noise = np.random.randint(-intensity, intensity, (stripe_thickness, w, c), dtype=np.int16)\n",
    "        start_row = min(i, h - stripe_thickness)\n",
    "        noisy_image[start_row:start_row + stripe_thickness] = np.clip(\n",
    "            noisy_image[start_row:start_row + stripe_thickness].astype(np.int16) + noise, 0, 255\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "def add_gaussian_noise_grayscale(image, mean=0, sigma=35):\n",
    "    image = image.astype(np.int16)\n",
    "    h, w, c = image.shape\n",
    "    noise = np.random.normal(mean, sigma, (h, w)).astype(np.int16)\n",
    "    noisy_image = np.clip(image + noise[:, :, np.newaxis], 0, 255).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "def add_noise_to_images(input_dir, output_dir, mean=0, sigma=35):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng ·∫£nh ph·ªï bi·∫øn\n",
    "    supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(supported_formats):\n",
    "            img_path = os.path.join(input_dir, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {filename}\")\n",
    "                continue\n",
    "\n",
    "            noisy_image = add_gaussian_noise_grayscale(image, mean, sigma)\n",
    "\n",
    "            out_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(out_path, noisy_image)\n",
    "            print(f\"ƒê√£ x·ª≠ l√Ω: {filename}\")\n",
    "\n",
    "# üîß Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ·ª©ng v·ªõi m√°y b·∫°n:\n",
    "input_dir = \"./input_images\"     # Th∆∞ m·ª•c ch·ª©a ·∫£nh g·ªëc\n",
    "output_dir = \"./noisy_images\"    # Th∆∞ m·ª•c ƒë·ªÉ l∆∞u ·∫£nh c√≥ nhi·ªÖu\n",
    "\n",
    "add_noise_to_images(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import fft2, ifft2, fftshift, ifftshift\n",
    "from scipy.signal import fftconvolve\n",
    "from bm3d import gaussian_kernel\n",
    "from typing import Tuple\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def get_experiment_kernel(noise_type: str, noise_var: float, sz: tuple = np.array((101, 101))):\n",
    "    \"\"\"\n",
    "    Get kernel for generating noise from specific experiment from the paper.\n",
    "    :param noise_type: Noise type string, g[0-4](w|)\n",
    "    :param noise_var: noise variance\n",
    "    :param sz: size of image, used only for g4 and g4w\n",
    "    :return: experiment kernel with the l2-norm equal to variance\n",
    "    \"\"\"\n",
    "    # if noiseType == gw / g0\n",
    "    kernel = np.array([[1]])\n",
    "    noise_types = ['gw', 'g0', 'g1', 'g2', 'g3', 'g4', 'g1w', 'g2w', 'g3w', 'g4w']\n",
    "    if noise_type not in noise_types:\n",
    "        raise ValueError(\"Noise type must be one of \" + str(noise_types))\n",
    "\n",
    "    if noise_type != \"g4\" and noise_type != \"g4w\":\n",
    "        # Crop this size of kernel when generating,\n",
    "        # unless pink noise, in which\n",
    "        # if noiseType == we want to use the full image size\n",
    "        sz = np.array([101, 101])\n",
    "    else:\n",
    "        sz = np.array(sz)\n",
    "\n",
    "    # Sizes for meshgrids\n",
    "    sz2 = -(1 - (sz % 2)) * 1 + np.floor(sz / 2)\n",
    "    sz1 = np.floor(sz / 2)\n",
    "    uu, vv = np.meshgrid([i for i in range(-int(sz1[0]), int(sz2[0]) + 1)],\n",
    "                         [i for i in range(-int(sz1[1]), int(sz2[1]) + 1)])\n",
    "\n",
    "    beta = 0.8\n",
    "\n",
    "    if noise_type[0:2] == 'g1':\n",
    "        # Horizontal line\n",
    "        kernel = np.atleast_2d(16 - abs(np.linspace(1, 31, 31) - 16))\n",
    "\n",
    "    elif noise_type[0:2] == 'g2':\n",
    "        # Circular repeating pattern\n",
    "        scale = 1\n",
    "        dist = uu ** 2 + vv ** 2\n",
    "        kernel = np.cos(np.sqrt(dist) / scale) * gaussian_kernel((sz[0], sz[1]), 10)\n",
    "\n",
    "    elif noise_type[0:2] == 'g3':\n",
    "        # Diagonal line pattern kernel\n",
    "        scale = 1\n",
    "        kernel = np.cos((uu + vv) / scale) * gaussian_kernel((sz[0], sz[1]), 10)\n",
    "\n",
    "    elif noise_type[0:2] == 'g4':\n",
    "        # Pink noise\n",
    "        dist = uu ** 2 + vv ** 2\n",
    "        n = sz[0] * sz[1]\n",
    "        spec = (np.sqrt((np.sqrt(n) * 1e-2) / (np.sqrt(dist) + np.sqrt(n) * 1e-2)))\n",
    "        kernel = fftshift(ifft2(ifftshift(spec)))\n",
    "\n",
    "    else:  # gw and g0 are white\n",
    "        beta = 0\n",
    "\n",
    "    # -- Noise with additional white component --\n",
    "\n",
    "    if len(noise_type) > 2 and noise_type[2] == 'w':\n",
    "        kernel = kernel / np.sqrt(np.sum(kernel ** 2))\n",
    "        kalpha = np.sqrt((1 - beta) + beta * abs(fft2(kernel, (sz[0], sz[1]))) ** 2)\n",
    "        kernel = fftshift(ifft2(kalpha))\n",
    "\n",
    "    kernel = np.real(kernel)\n",
    "    # Correct variance\n",
    "    kernel = kernel / np.sqrt(np.sum(kernel ** 2)) * np.sqrt(noise_var)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def get_experiment_noise(noise_type: str, noise_var: float, realization: int, sz: tuple)\\\n",
    "        -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate noise for experiment with specified kernel, variance, seed and size.\n",
    "    Return noise and relevant parameters.\n",
    "    The generated noise is non-circular.\n",
    "    :param noise_type: Noise type, see get_experiment_kernel for list of accepted types.\n",
    "    :param noise_var: Noise variance of the resulting noise\n",
    "    :param realization: Seed for the noise realization\n",
    "    :param sz: image size -> size of resulting noise\n",
    "    :return: noise, PSD, and kernel\n",
    "    \"\"\"\n",
    "    np.random.seed(realization)\n",
    "\n",
    "    # Get pre-specified kernel\n",
    "    kernel = get_experiment_kernel(noise_type, noise_var, sz)\n",
    "\n",
    "    # Create noisy image\n",
    "    half_kernel = np.ceil(np.array(kernel.shape) / 2)\n",
    "\n",
    "    if len(sz) == 3 and half_kernel.size == 2:\n",
    "        half_kernel = [half_kernel[0], half_kernel[1], 0]\n",
    "        kernel = np.atleast_3d(kernel)\n",
    "\n",
    "    half_kernel = np.array(half_kernel, dtype=int)\n",
    "\n",
    "    # Crop edges\n",
    "    noise = fftconvolve(np.random.normal(size=(sz + 2 * half_kernel)), kernel, mode='same')\n",
    "    noise = np.atleast_3d(noise)[half_kernel[0]:-half_kernel[0], half_kernel[1]:-half_kernel[1], :]\n",
    "\n",
    "    psd = abs(fft2(kernel, (sz[0], sz[1]), axes=(0, 1))) ** 2 * sz[0] * sz[1]\n",
    "\n",
    "    return noise, psd, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagepath = '/home/duongnhan/Chon/MWFormer/data/CT/gt/'\n",
    "imagename = imagepath + 'image_s0001_i0021.jpg'\n",
    "y = np.array(Image.open(imagename)) / 255\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "imagepath = 'dataset/dataset_structure'\n",
    "imagename = imagepath + '/ref/1.png'\n",
    "# Load noise-free image\n",
    "y = Image.open(imagename).convert('L')\n",
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "\n",
    "noise_list = ['g1', 'g2', 'g3', 'g4']\n",
    "noise_type = random.choice(noise_list)\n",
    "print(noise_type)\n",
    "sigma = 25\n",
    "noise_var = (sigma/255)**2  # Noise variance 25 std\n",
    "seed = 8  # seed for pseudorandom noise realization\n",
    "\n",
    "# Generate noise with given PSD\n",
    "noise, psd, kernel = get_experiment_noise(noise_type, noise_var, seed, (64, 64))\n",
    "# N.B.: For the sake of simulating a more realistic acquisition scenario,\n",
    "# the generated noise is *not* circulant. Therefore there is a slight\n",
    "# discrepancy between PSD and the actual PSD computed from infinitely many\n",
    "# realizations of this noise with different seeds.\n",
    "\n",
    "\n",
    "# Generate noisy image corrupted by additive spatially correlated noise\n",
    "# with noise power spectrum PSD\n",
    "# z = np.atleast_3d(y) + np.atleast_3d(noise)\n",
    "print(y.shape)\n",
    "print(noise.shape)\n",
    "z = y + noise\n",
    "print(z.shape)\n",
    "z_rang = np.minimum(np.maximum(z, 0), 1)\n",
    "print(z_rang.shape)\n",
    "imagepath = 'dataset/brain/train/noisy/'\n",
    "noisyimagename=imagepath + '33.png'\n",
    "plt.imsave(noisyimagename, z_rang, cmap='gray') \n",
    "#y_est = np.array(Image.open(noisyimagename)) / 255\n",
    "# Call BM3D With the default settings.\n",
    "#y_est = bm3d_rgb(z, psd)\n",
    "\n",
    "\n",
    "# To include refiltering:\n",
    "# y_est = bm3d_rgb(z, psd, 'refilter');\n",
    "\n",
    "# For other settings, use BM3DProfile.\n",
    "# profile = BM3DProfile(); # equivalent to profile = BM3DProfile('np');\n",
    "# profile.gamma = 6;  # redefine value of gamma parameter\n",
    "# y_est = bm3d_rgb(z, psd, profile);\n",
    "\n",
    "# Note: For white noise, you may instead of the PSD\n",
    "# also pass a standard deviation\n",
    "# y_est = bm3d_rgb(z, sqrt(noise_var));\n",
    "\n",
    "# If the different channels have varying PSDs, you can supply a MxNx3 PSD or a list of 3 STDs:\n",
    "# y_est = bm3d_rgb(z, np.concatenate((psd1, psd2, psd3), 2))\n",
    "# y_est = bm3d_rgb(z, [sigma1, sigma2, sigma3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean image shape: (512, 512, 3)\n",
      "Noise type: g1\n",
      "Noise shape: (512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh b·ªã nhi·ªÖu t·∫°i: /home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from pathlib import Path\n",
    "\n",
    "# === ƒê∆∞·ªùng d·∫´n ·∫£nh v√† n∆°i l∆∞u ===\n",
    "imagepath = ('/home/duongnhan/Chon/MWFormer/data/CT/gt/image_s0001_i0021.jpg')\n",
    "savepath = ('/home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg')\n",
    "# savepath.parent.mkdir(parents=True, exist_ok=True)  # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "\n",
    "# === Load ·∫£nh s·∫°ch v√† chuy·ªÉn th√†nh RGB (512, 512, 3) ===\n",
    "img = Image.open(imagepath).convert(\"RGB\")\n",
    "img_np = np.array(img) / 255.0  # Normalize v·ªÅ [0,1]\n",
    "print(\"Clean image shape:\", img_np.shape)  # (512, 512, 3)\n",
    "y = Image.open(imagepath).convert('RGB')\n",
    "y = np.array(y)\n",
    "\n",
    "# === Ch·ªçn lo·∫°i nhi·ªÖu v√† thi·∫øt l·∫≠p tham s·ªë ===\n",
    "noise_list = ['g1', 'g2', 'g3', 'g4']\n",
    "# noise_type = random.choice(noise_list)\n",
    "noise_type = 'g1'\n",
    "print(\"Noise type:\", noise_type)\n",
    "\n",
    "sigma = 25\n",
    "noise_var = (sigma / 255.0) ** 2  # Ph∆∞∆°ng sai nhi·ªÖu\n",
    "seed = 8  # Random seed ƒë·ªÉ t√°i hi·ªán ƒë∆∞·ª£c\n",
    "\n",
    "# === Sinh nhi·ªÖu c√≥ c·∫•u tr√∫c ===\n",
    "# from your_module import get_experiment_noise  # üîÅ thay b·∫±ng ƒë√∫ng n∆°i b·∫°n import h√†m\n",
    "\n",
    "noise, psd, kernel = get_experiment_noise(\n",
    "    noise_type=noise_type,\n",
    "    noise_var=noise_var,\n",
    "    realization=seed,\n",
    "    sz=img_np.shape  # (512, 512, 3)\n",
    ")\n",
    "\n",
    "print(\"Noise shape:\", noise.shape)\n",
    "\n",
    "# === C·ªông nhi·ªÖu v√†o ·∫£nh g·ªëc v√† clamp v·ªÅ [0,1] ===\n",
    "# noisy_img = np.clip(img_np + noise, 0, 1)\n",
    "\n",
    "print(y.shape)\n",
    "print(noise.shape)\n",
    "z = np.atleast_3d(y) + np.atleast_3d(noise)\n",
    "# z = y + noise\n",
    "print(z.shape)\n",
    "z_rang = np.minimum(np.maximum(z, 0), 1)\n",
    "print(z_rang.shape)\n",
    "\n",
    "# === L∆∞u ·∫£nh ƒë√£ b·ªã nhi·ªÖu ===\n",
    "# Convert ·∫£nh v·ªÅ ƒë√∫ng ƒë·ªãnh d·∫°ng [0,255], uint8, BGR\n",
    "z_uint8 = (z_rang * 255).astype(np.uint8)\n",
    "z_bgr = cv2.cvtColor(z_uint8, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# L∆∞u ·∫£nh b·∫±ng OpenCV\n",
    "cv2.imwrite(savepath, z_bgr)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u ·∫£nh b·ªã nhi·ªÖu t·∫°i: {savepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagepath = '/home/duongnhan/Chon/MWFormer/data/CT/input/'\n",
    "imagename = imagepath + 'image_s0001_i0021.jpg'\n",
    "y = np.array(Image.open(imagename)) / 255\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 4, 2],\n",
       "       [0, 0, 0, ..., 2, 6, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.05992104],\n",
       "        [-0.0440739 ],\n",
       "        [-0.03352228],\n",
       "        ...,\n",
       "        [ 0.07169429],\n",
       "        [ 0.08512972],\n",
       "        [ 0.0993957 ]],\n",
       "\n",
       "       [[-0.13490802],\n",
       "        [-0.13744579],\n",
       "        [-0.13811942],\n",
       "        ...,\n",
       "        [ 0.04495801],\n",
       "        [ 0.03608688],\n",
       "        [ 0.03162288]],\n",
       "\n",
       "       [[-0.11379481],\n",
       "        [-0.11235925],\n",
       "        [-0.11189128],\n",
       "        ...,\n",
       "        [-0.03515404],\n",
       "        [-0.03593724],\n",
       "        [-0.03786273]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.19565049],\n",
       "        [ 0.1951895 ],\n",
       "        [ 0.18967023],\n",
       "        ...,\n",
       "        [-0.18148091],\n",
       "        [-0.18155723],\n",
       "        [-0.17228258]],\n",
       "\n",
       "       [[-0.02704226],\n",
       "        [-0.04068443],\n",
       "        [-0.04725832],\n",
       "        ...,\n",
       "        [-0.05510122],\n",
       "        [-0.04289968],\n",
       "        [-0.03069778]],\n",
       "\n",
       "       [[ 0.1576523 ],\n",
       "        [ 0.15468969],\n",
       "        [ 0.15408522],\n",
       "        ...,\n",
       "        [-0.06313315],\n",
       "        [-0.04371583],\n",
       "        [-0.02648343]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise type: g4\n",
      "Broadcasted noise shape: (512, 512)\n",
      "Noise shape: (512, 512, 3)\n",
      "(512, 512, 3)\n",
      "‚úÖ ·∫¢nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i /home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from pathlib import Path\n",
    "\n",
    "# === ƒê∆∞·ªùng d·∫´n ·∫£nh v√† n∆°i l∆∞u ===\n",
    "imagepath = ('/home/duongnhan/Chon/MWFormer/data/CT/gt/image_s0001_i0021.jpg')\n",
    "savepath = ('/home/duongnhan/Chon/MWFormer/data/CT/input/image_s0001_i0021.jpg')\n",
    "# savepath.parent.mkdir(parents=True, exist_ok=True)  # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "\n",
    "# === Load ·∫£nh s·∫°ch v√† chuy·ªÉn th√†nh RGB (512, 512, 3) ===\n",
    "y = Image.open(imagepath).convert('RGB')\n",
    "y = np.array(y)\n",
    "\n",
    "# === Ch·ªçn lo·∫°i nhi·ªÖu v√† thi·∫øt l·∫≠p tham s·ªë ===\n",
    "noise_list = ['g1', 'g2', 'g3', 'g4']\n",
    "# noise_type = random.choice(noise_list)\n",
    "noise_type = 'g4'\n",
    "print(\"Noise type:\", noise_type)\n",
    "\n",
    "sigma = 25\n",
    "noise_var = (sigma / 255.0) ** 2  # Ph∆∞∆°ng sai nhi·ªÖu\n",
    "seed = 8  # Random seed ƒë·ªÉ t√°i hi·ªán ƒë∆∞·ª£c\n",
    "\n",
    "# === Sinh nhi·ªÖu c√≥ c·∫•u tr√∫c ===\n",
    "\n",
    "gray_noise, psd, kernel = get_experiment_noise(\n",
    "    noise_type=noise_type,\n",
    "    noise_var=noise_var,\n",
    "    realization=seed,\n",
    "    # sz=img_np.shape  # (512, 512, 3)\n",
    "    # sz = (512, 512, 3)\n",
    "    sz = (512, 512)\n",
    ")\n",
    "# noise = np.repeat(gray_noise[:, :, np.newaxis], 3, axis=2)  # shape: (512, 512, 3)\n",
    "gray_noise = np.squeeze(gray_noise)  # K·∫øt qu·∫£: (512, 512)\n",
    "noise = np.stack([gray_noise] * 3, axis=2)  # (512, 512, 3)\n",
    "\n",
    "print(\"Broadcasted noise shape:\", gray_noise.shape)\n",
    "print(\"Noise shape:\", noise.shape)\n",
    "\n",
    "# === C·ªông nhi·ªÖu v√†o ·∫£nh g·ªëc v√† clamp v·ªÅ [0,1] ===\n",
    "\n",
    "# Chuy·ªÉn ·∫£nh s·∫°ch v·ªÅ float [0, 1]\n",
    "y = y.astype(np.float32) / 255.0\n",
    "z = y + noise\n",
    "print(z.shape)\n",
    "\n",
    "z_clamped = np.clip(z, 0, 1)  # ƒê·∫£m b·∫£o kh√¥ng tr√†n m√†u\n",
    "z_uint8 = (z_clamped * 255).astype(np.uint8)\n",
    "\n",
    "z_bgr = cv2.cvtColor(z_uint8, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(savepath, z_bgr)\n",
    "print(f\"‚úÖ ·∫¢nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i {savepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_uint8.shape = (512, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"z_uint8.shape =\", z_clamped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def apply_structured_noise_to_folder(\n",
    "    input_dir,\n",
    "    output_gt_dir,\n",
    "    output_noisy_dir,\n",
    "    output_txt_path,\n",
    "    noise_types=['g1', 'g4'],\n",
    "    sigma=25,\n",
    "    seed=8\n",
    "):\n",
    "    image_paths = list(Path(input_dir).glob(\"*.jpg\"))  # you can adjust for .png if needed\n",
    "    os.makedirs(output_gt_dir, exist_ok=True)\n",
    "    os.makedirs(output_noisy_dir, exist_ok=True)\n",
    "\n",
    "    output_txt = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        base_name = image_path.stem  # Get filename without extension\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img_np = np.array(img).astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "\n",
    "        for noise_type in noise_types:\n",
    "            noise, _, _ = get_experiment_noise(\n",
    "                noise_type=noise_type,\n",
    "                noise_var=(sigma / 255.0) ** 2,\n",
    "                realization=seed,\n",
    "                sz=(img_np.shape[0], img_np.shape[1])\n",
    "            )\n",
    "\n",
    "            # Expand grayscale noise to 3 channels\n",
    "            noise = np.repeat(np.squeeze(noise)[:, :, np.newaxis], 3, axis=2)\n",
    "            noisy_img = np.clip(img_np + noise, 0, 1)\n",
    "            noisy_uint8 = (noisy_img * 255).astype(np.uint8)\n",
    "\n",
    "            # Save clean GT image (once per noise_type)\n",
    "            gt_filename = f\"{base_name}_{noise_type}.jpg\"\n",
    "            gt_path = os.path.join(output_gt_dir, gt_filename)\n",
    "            cv2.imwrite(gt_path, cv2.cvtColor((img_np * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Save noisy image\n",
    "            noisy_filename = f\"{base_name}_{noise_type}.jpg\"\n",
    "            noisy_path = os.path.join(output_noisy_dir, noisy_filename)\n",
    "            cv2.imwrite(noisy_path, cv2.cvtColor(noisy_uint8, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Write noisy path to output list\n",
    "            output_txt.append(noisy_path)\n",
    "\n",
    "    # Save CT.txt with all noisy image paths\n",
    "    with open(output_txt_path, \"w\") as f:\n",
    "        for path in output_txt:\n",
    "            f.write(path + \"\\n\")\n",
    "\n",
    "    # return output_txt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_structured_noise_to_folder(\n",
    "    input_dir='/home/duongnhan/Chon/Capstone_project/Backend/PMRF/data/split_data/train',  # th∆∞ m·ª•c ch·ª©a ·∫£nh g·ªëc\n",
    "    output_gt_dir='./data/CT25_split/train/gt',    # n∆°i l∆∞u ·∫£nh s·∫°ch g·ªëc+_g1/g4\n",
    "    output_noisy_dir='./data/CT25_split/train/input',  # n∆°i l∆∞u ·∫£nh nhi·ªÖu\n",
    "    output_txt_path='./data/CT25_split/train/CT.txt',  # n∆°i ghi ƒë∆∞·ªùng d·∫´n ·∫£nh nhi·ªÖu\n",
    "    noise_types=['g1', 'g4'],  # c√°c lo·∫°i nhi·ªÖu mu·ªën √°p d·ª•ng\n",
    "    sigma=25,  # ƒë·ªô l·ªách chu·∫©n\n",
    "    seed=8     # ƒë·ªÉ t√°i l·∫≠p nhi·ªÖu\n",
    ")\n",
    "apply_structured_noise_to_folder(\n",
    "    input_dir='/home/duongnhan/Chon/Capstone_project/Backend/PMRF/data/split_data/test',  # th∆∞ m·ª•c ch·ª©a ·∫£nh g·ªëc\n",
    "    output_gt_dir='./data/CT25_split/test/gt',    # n∆°i l∆∞u ·∫£nh s·∫°ch g·ªëc+_g1/g4\n",
    "    output_noisy_dir='./data/CT25_split/test/input',  # n∆°i l∆∞u ·∫£nh nhi·ªÖu\n",
    "    output_txt_path='./data/CT25_split/test/CT.txt',  # n∆°i ghi ƒë∆∞·ªùng d·∫´n ·∫£nh nhi·ªÖu\n",
    "    noise_types=['g1', 'g4'],  # c√°c lo·∫°i nhi·ªÖu mu·ªën √°p d·ª•ng\n",
    "    sigma=25,  # ƒë·ªô l·ªách chu·∫©n\n",
    "    seed=8     # ƒë·ªÉ t√°i l·∫≠p nhi·ªÖu\n",
    ")\n",
    "apply_structured_noise_to_folder(\n",
    "    input_dir='/home/duongnhan/Chon/Capstone_project/Backend/PMRF/data/split_data/val',  # th∆∞ m·ª•c ch·ª©a ·∫£nh g·ªëc\n",
    "    output_gt_dir='./data/CT25_split/val/gt',    # n∆°i l∆∞u ·∫£nh s·∫°ch g·ªëc+_g1/g4\n",
    "    output_noisy_dir='./data/CT25_split/val/input',  # n∆°i l∆∞u ·∫£nh nhi·ªÖu\n",
    "    output_txt_path='./data/CT25_split/val/CT.txt',  # n∆°i ghi ƒë∆∞·ªùng d·∫´n ·∫£nh nhi·ªÖu\n",
    "    noise_types=['g1', 'g4'],  # c√°c lo·∫°i nhi·ªÖu mu·ªën √°p d·ª•ng\n",
    "    sigma=25,  # ƒë·ªô l·ªách chu·∫©n\n",
    "    seed=8     # ƒë·ªÉ t√°i l·∫≠p nhi·ªÖu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mruntest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_test  \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file ·∫£nh t·∫°m th·ªùi\u001b[39;00m\n",
      "File \u001b[0;32m~/Chon/Capstone_project/Backend/ModelAI/MWFormer/runtest.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval_data_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ValData\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_val\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validation_stylevec, validation_stylevec2 \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "from runtest import run_test  \n",
    "import argparse\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file ·∫£nh t·∫°m th·ªùi\n",
    "UPLOAD_FOLDER = \"./uploads\"\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "# L·∫•y c√°c tham s·ªë ƒë·ªÉ g·ªçi `run_test`\n",
    "parser = argparse.ArgumentParser(description='Hyper-parameters for network')\n",
    "parser.add_argument('-val_batch_size', help='Set the validation/test batch size', default=1, type=int)\n",
    "parser.add_argument('-seed', help='set random seed', default=19, type=int)\n",
    "parser.add_argument(\"-restore-from-stylefilter\", help='the weights of feature extraction network', type=str, default='/home/duongnhan/Chon/MWFormer/ckpt/lan4/finetune/finetune3/style_best_all')\n",
    "parser.add_argument('-restore-from-backbone', help='the weights of the image restoration backbone', default='/home/duongnhan/Chon/MWFormer/ckpt/lan4/finetune/finetune3/finetune4_3190000.pth', type=str)     \n",
    "parser.add_argument('-val_data_dir', default='/home/duongnhan/Chon/Capstone_project/Backend/ModelAI/MWFormer/data/CT_test/', type=str)  # Ch·ªâ ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c upload ·∫£nh\n",
    "parser.add_argument('-val_filename', default='CT.txt', type=str)  # S·ª≠ d·ª•ng t√™n file c·ªßa ·∫£nh v·ª´a t·∫£i l√™n\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Ch·∫°y h√†m test.py\n",
    "try:\n",
    "    psnr, ssim = run_test(args)  # G·ªçi h√†m test v·ªõi c√°c tham s·ªë ƒë√£ ƒë·ªãnh nghƒ©a\n",
    "    print('val_psnr thu: {0:.2f}, val_ssim thu: {1:.4f}'.format(psnr, ssim))\n",
    "    # return {\"message\": \"Image denoising completed successfully\"}\n",
    "except Exception as e:\n",
    "    # return {\"error\": str(e)}\n",
    "    print(\"Eror:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
